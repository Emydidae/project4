{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f93f1982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code by Peter Solis\n",
    "# dependencies\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4daf6636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - Dropout\n",
      "1 - Graduate\n",
      "2 - Enrolled\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PCA1</th>\n",
       "      <th>PCA2</th>\n",
       "      <th>PCA3</th>\n",
       "      <th>PCA4</th>\n",
       "      <th>PCA5</th>\n",
       "      <th>PCA6</th>\n",
       "      <th>PCA7</th>\n",
       "      <th>PCA8</th>\n",
       "      <th>PCA9</th>\n",
       "      <th>PCA10</th>\n",
       "      <th>...</th>\n",
       "      <th>Curricular units 1st sem (without evaluations)</th>\n",
       "      <th>Curricular units 2nd sem (credited)</th>\n",
       "      <th>Curricular units 2nd sem (enrolled)</th>\n",
       "      <th>Curricular units 2nd sem (evaluations)</th>\n",
       "      <th>Curricular units 2nd sem (approved)</th>\n",
       "      <th>Curricular units 2nd sem (grade)</th>\n",
       "      <th>Curricular units 2nd sem (without evaluations)</th>\n",
       "      <th>Unemployment rate</th>\n",
       "      <th>Inflation rate</th>\n",
       "      <th>GDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.162155</td>\n",
       "      <td>0.028002</td>\n",
       "      <td>-0.871987</td>\n",
       "      <td>-0.003519</td>\n",
       "      <td>-0.282296</td>\n",
       "      <td>-0.504824</td>\n",
       "      <td>-0.168469</td>\n",
       "      <td>-0.306896</td>\n",
       "      <td>0.555613</td>\n",
       "      <td>-0.052945</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.199273</td>\n",
       "      <td>-0.282442</td>\n",
       "      <td>-2.838337</td>\n",
       "      <td>-2.042630</td>\n",
       "      <td>-1.471527</td>\n",
       "      <td>-1.963489</td>\n",
       "      <td>-0.199441</td>\n",
       "      <td>-0.287638</td>\n",
       "      <td>0.124386</td>\n",
       "      <td>0.765761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.230439</td>\n",
       "      <td>-0.508801</td>\n",
       "      <td>-0.888205</td>\n",
       "      <td>-0.126158</td>\n",
       "      <td>-0.399622</td>\n",
       "      <td>0.015986</td>\n",
       "      <td>-0.086921</td>\n",
       "      <td>-0.037612</td>\n",
       "      <td>-0.101045</td>\n",
       "      <td>0.013282</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.199273</td>\n",
       "      <td>-0.282442</td>\n",
       "      <td>-0.105726</td>\n",
       "      <td>-0.522682</td>\n",
       "      <td>0.518904</td>\n",
       "      <td>0.659562</td>\n",
       "      <td>-0.199441</td>\n",
       "      <td>0.876222</td>\n",
       "      <td>-1.105222</td>\n",
       "      <td>0.347199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.442844</td>\n",
       "      <td>0.679992</td>\n",
       "      <td>-1.137401</td>\n",
       "      <td>-0.198085</td>\n",
       "      <td>-0.015669</td>\n",
       "      <td>0.027037</td>\n",
       "      <td>-0.076970</td>\n",
       "      <td>-0.163251</td>\n",
       "      <td>0.026286</td>\n",
       "      <td>0.334927</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.199273</td>\n",
       "      <td>-0.282442</td>\n",
       "      <td>-0.105726</td>\n",
       "      <td>-2.042630</td>\n",
       "      <td>-1.471527</td>\n",
       "      <td>-1.963489</td>\n",
       "      <td>-0.199441</td>\n",
       "      <td>-0.287638</td>\n",
       "      <td>0.124386</td>\n",
       "      <td>0.765761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.720106</td>\n",
       "      <td>-0.190385</td>\n",
       "      <td>-0.002961</td>\n",
       "      <td>-0.299306</td>\n",
       "      <td>-0.633617</td>\n",
       "      <td>-0.209809</td>\n",
       "      <td>-0.348117</td>\n",
       "      <td>-0.191423</td>\n",
       "      <td>0.111372</td>\n",
       "      <td>-0.142614</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.199273</td>\n",
       "      <td>-0.282442</td>\n",
       "      <td>-0.105726</td>\n",
       "      <td>0.490616</td>\n",
       "      <td>0.187165</td>\n",
       "      <td>0.416450</td>\n",
       "      <td>-0.199441</td>\n",
       "      <td>-0.813253</td>\n",
       "      <td>-1.466871</td>\n",
       "      <td>-1.375511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.459906</td>\n",
       "      <td>0.612459</td>\n",
       "      <td>0.796140</td>\n",
       "      <td>-0.487460</td>\n",
       "      <td>-0.180109</td>\n",
       "      <td>-0.687948</td>\n",
       "      <td>0.330021</td>\n",
       "      <td>-0.474441</td>\n",
       "      <td>-0.070128</td>\n",
       "      <td>0.051929</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.199273</td>\n",
       "      <td>-0.282442</td>\n",
       "      <td>-0.105726</td>\n",
       "      <td>-0.522682</td>\n",
       "      <td>0.518904</td>\n",
       "      <td>0.531608</td>\n",
       "      <td>-0.199441</td>\n",
       "      <td>0.876222</td>\n",
       "      <td>-1.105222</td>\n",
       "      <td>0.347199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PCA1      PCA2      PCA3      PCA4      PCA5      PCA6      PCA7  \\\n",
       "0 -0.162155  0.028002 -0.871987 -0.003519 -0.282296 -0.504824 -0.168469   \n",
       "1 -0.230439 -0.508801 -0.888205 -0.126158 -0.399622  0.015986 -0.086921   \n",
       "2  0.442844  0.679992 -1.137401 -0.198085 -0.015669  0.027037 -0.076970   \n",
       "3 -0.720106 -0.190385 -0.002961 -0.299306 -0.633617 -0.209809 -0.348117   \n",
       "4  1.459906  0.612459  0.796140 -0.487460 -0.180109 -0.687948  0.330021   \n",
       "\n",
       "       PCA8      PCA9     PCA10  ...  \\\n",
       "0 -0.306896  0.555613 -0.052945  ...   \n",
       "1 -0.037612 -0.101045  0.013282  ...   \n",
       "2 -0.163251  0.026286  0.334927  ...   \n",
       "3 -0.191423  0.111372 -0.142614  ...   \n",
       "4 -0.474441 -0.070128  0.051929  ...   \n",
       "\n",
       "   Curricular units 1st sem (without evaluations)  \\\n",
       "0                                       -0.199273   \n",
       "1                                       -0.199273   \n",
       "2                                       -0.199273   \n",
       "3                                       -0.199273   \n",
       "4                                       -0.199273   \n",
       "\n",
       "   Curricular units 2nd sem (credited)  Curricular units 2nd sem (enrolled)  \\\n",
       "0                            -0.282442                            -2.838337   \n",
       "1                            -0.282442                            -0.105726   \n",
       "2                            -0.282442                            -0.105726   \n",
       "3                            -0.282442                            -0.105726   \n",
       "4                            -0.282442                            -0.105726   \n",
       "\n",
       "   Curricular units 2nd sem (evaluations)  \\\n",
       "0                               -2.042630   \n",
       "1                               -0.522682   \n",
       "2                               -2.042630   \n",
       "3                                0.490616   \n",
       "4                               -0.522682   \n",
       "\n",
       "   Curricular units 2nd sem (approved)  Curricular units 2nd sem (grade)  \\\n",
       "0                            -1.471527                         -1.963489   \n",
       "1                             0.518904                          0.659562   \n",
       "2                            -1.471527                         -1.963489   \n",
       "3                             0.187165                          0.416450   \n",
       "4                             0.518904                          0.531608   \n",
       "\n",
       "   Curricular units 2nd sem (without evaluations)  Unemployment rate  \\\n",
       "0                                       -0.199441          -0.287638   \n",
       "1                                       -0.199441           0.876222   \n",
       "2                                       -0.199441          -0.287638   \n",
       "3                                       -0.199441          -0.813253   \n",
       "4                                       -0.199441           0.876222   \n",
       "\n",
       "   Inflation rate       GDP  \n",
       "0        0.124386  0.765761  \n",
       "1       -1.105222  0.347199  \n",
       "2        0.124386  0.765761  \n",
       "3       -1.466871 -1.375511  \n",
       "4       -1.105222  0.347199  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do all the formatting, this is copied from the supervised learning models\n",
    "# read in data\n",
    "df = pd.read_csv('../01 - Data Crunching/dataset.csv')\n",
    "\n",
    "# translating our target into categorical values for these models to work with\n",
    "# https://www.codementor.io/@agarrahul01/multiclass-classification-using-random-forest-on-scikit-learn-library-hkk4lwawu was referenced for how to make a tree / forest model with these in mind\n",
    "target_names = pd.factorize(df['Target'])[1]\n",
    "df['Target'] = pd.factorize(df['Target'])[0]\n",
    "for i in range(len(target_names)):\n",
    "    print(f'{i} - {target_names[i]}')\n",
    "    \n",
    "# split based on data type\n",
    "categorical_df = df.iloc[:,[0,1,3,4,5,6,7,8,9,10,11,12,13,14,15,16,18]].copy()\n",
    "numerical_df = df.iloc[:,[2,17,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33]].copy()\n",
    "y = df[['Target']].copy()\n",
    "\n",
    "# make non-binary categorical columns clearly categorical - you may want to also bin these in some cases\n",
    "# more info on what each category means can be found here:\n",
    "# https://www.mdpi.com/2306-5729/7/11/146\n",
    "def categorize(cell):\n",
    "    return f'cat_{cell}'\n",
    "col_to_adjust = ['Marital status',\n",
    "                 'Application mode',\n",
    "                 'Course',\n",
    "                 'Previous qualification',\n",
    "                 'Nacionality',\n",
    "                 \"Mother's qualification\",\n",
    "                 \"Father's qualification\",\n",
    "                 \"Mother's occupation\",\n",
    "                 \"Father's occupation\"]\n",
    "for col in col_to_adjust:\n",
    "    categorical_df[col] = categorical_df[col].apply(categorize)\n",
    "\n",
    "# finish pre-processing categorical data\n",
    "# I referenced the tables of most important variables found in the cell above, and decided to exclude some categorical data that didn't play a huge role and would greatly increase the number of columns\n",
    "# important categorical data with tons of values\n",
    "to_drop = [\"Application mode\",\n",
    "           \"Nacionality\",\n",
    "           \"Mother's qualification\",\n",
    "           \"Father's qualification\"]\n",
    "cat_df_2 = pd.get_dummies(categorical_df.drop(columns = to_drop, axis = 1))\n",
    "# try using PCA to deal with the huge number of values, we'll give it twice the number of columns of the actual values\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 10)\n",
    "pca_cat_df = pd.DataFrame(pca.fit_transform(cat_df_2), columns = ['PCA1','PCA2','PCA3','PCA4','PCA5','PCA6','PCA7','PCA8','PCA9','PCA10'])\n",
    "\n",
    "# these are the categorical columns that stay as one column\n",
    "others = ['Daytime/evening attendance',\n",
    "          'Displaced',\n",
    "          'Educational special needs',\n",
    "          'Debtor',\n",
    "          'Tuition fees up to date',\n",
    "          'Gender',\n",
    "          'Scholarship holder',\n",
    "          'International']\n",
    "parsed_cat_df = pd.concat([pca_cat_df, categorical_df[others]], axis = 1)\n",
    "\n",
    "# finish preprocessing by scaling and doing PCA\n",
    "scaled_num_df = pd.DataFrame(StandardScaler().fit_transform(numerical_df), columns = numerical_df.columns)\n",
    "final_df = pd.concat([parsed_cat_df, scaled_num_df], axis = 1)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4cb9455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Marital status</th>\n",
       "      <th>Application mode</th>\n",
       "      <th>Application order</th>\n",
       "      <th>Course</th>\n",
       "      <th>Daytime/evening attendance</th>\n",
       "      <th>Previous qualification</th>\n",
       "      <th>Nacionality</th>\n",
       "      <th>Mother's qualification</th>\n",
       "      <th>Father's qualification</th>\n",
       "      <th>Mother's occupation</th>\n",
       "      <th>...</th>\n",
       "      <th>Curricular units 2nd sem (credited)</th>\n",
       "      <th>Curricular units 2nd sem (enrolled)</th>\n",
       "      <th>Curricular units 2nd sem (evaluations)</th>\n",
       "      <th>Curricular units 2nd sem (approved)</th>\n",
       "      <th>Curricular units 2nd sem (grade)</th>\n",
       "      <th>Curricular units 2nd sem (without evaluations)</th>\n",
       "      <th>Unemployment rate</th>\n",
       "      <th>Inflation rate</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.74</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>13.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>27</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.74</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>12.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-3.12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>28</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4419</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>-4.06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4420</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4421</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>27</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4422</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>27</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-3.12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4423</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>12.7</td>\n",
       "      <td>3.7</td>\n",
       "      <td>-1.70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4424 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Marital status  Application mode  Application order  Course  \\\n",
       "0                  1                 8                  5       2   \n",
       "1                  1                 6                  1      11   \n",
       "2                  1                 1                  5       5   \n",
       "3                  1                 8                  2      15   \n",
       "4                  2                12                  1       3   \n",
       "...              ...               ...                ...     ...   \n",
       "4419               1                 1                  6      15   \n",
       "4420               1                 1                  2      15   \n",
       "4421               1                 1                  1      12   \n",
       "4422               1                 1                  1       9   \n",
       "4423               1                 5                  1      15   \n",
       "\n",
       "      Daytime/evening attendance  Previous qualification  Nacionality  \\\n",
       "0                              1                       1            1   \n",
       "1                              1                       1            1   \n",
       "2                              1                       1            1   \n",
       "3                              1                       1            1   \n",
       "4                              0                       1            1   \n",
       "...                          ...                     ...          ...   \n",
       "4419                           1                       1            1   \n",
       "4420                           1                       1           19   \n",
       "4421                           1                       1            1   \n",
       "4422                           1                       1            1   \n",
       "4423                           1                       1            9   \n",
       "\n",
       "      Mother's qualification  Father's qualification  Mother's occupation  \\\n",
       "0                         13                      10                    6   \n",
       "1                          1                       3                    4   \n",
       "2                         22                      27                   10   \n",
       "3                         23                      27                    6   \n",
       "4                         22                      28                   10   \n",
       "...                      ...                     ...                  ...   \n",
       "4419                       1                       1                    6   \n",
       "4420                       1                       1                   10   \n",
       "4421                      22                      27                   10   \n",
       "4422                      22                      27                    8   \n",
       "4423                      23                      27                    6   \n",
       "\n",
       "      ...  Curricular units 2nd sem (credited)  \\\n",
       "0     ...                                    0   \n",
       "1     ...                                    0   \n",
       "2     ...                                    0   \n",
       "3     ...                                    0   \n",
       "4     ...                                    0   \n",
       "...   ...                                  ...   \n",
       "4419  ...                                    0   \n",
       "4420  ...                                    0   \n",
       "4421  ...                                    0   \n",
       "4422  ...                                    0   \n",
       "4423  ...                                    0   \n",
       "\n",
       "      Curricular units 2nd sem (enrolled)  \\\n",
       "0                                       0   \n",
       "1                                       6   \n",
       "2                                       6   \n",
       "3                                       6   \n",
       "4                                       6   \n",
       "...                                   ...   \n",
       "4419                                    6   \n",
       "4420                                    6   \n",
       "4421                                    8   \n",
       "4422                                    5   \n",
       "4423                                    6   \n",
       "\n",
       "      Curricular units 2nd sem (evaluations)  \\\n",
       "0                                          0   \n",
       "1                                          6   \n",
       "2                                          0   \n",
       "3                                         10   \n",
       "4                                          6   \n",
       "...                                      ...   \n",
       "4419                                       8   \n",
       "4420                                       6   \n",
       "4421                                       9   \n",
       "4422                                       6   \n",
       "4423                                       6   \n",
       "\n",
       "      Curricular units 2nd sem (approved)  Curricular units 2nd sem (grade)  \\\n",
       "0                                       0                          0.000000   \n",
       "1                                       6                         13.666667   \n",
       "2                                       0                          0.000000   \n",
       "3                                       5                         12.400000   \n",
       "4                                       6                         13.000000   \n",
       "...                                   ...                               ...   \n",
       "4419                                    5                         12.666667   \n",
       "4420                                    2                         11.000000   \n",
       "4421                                    1                         13.500000   \n",
       "4422                                    5                         12.000000   \n",
       "4423                                    6                         13.000000   \n",
       "\n",
       "      Curricular units 2nd sem (without evaluations)  Unemployment rate  \\\n",
       "0                                                  0               10.8   \n",
       "1                                                  0               13.9   \n",
       "2                                                  0               10.8   \n",
       "3                                                  0                9.4   \n",
       "4                                                  0               13.9   \n",
       "...                                              ...                ...   \n",
       "4419                                               0               15.5   \n",
       "4420                                               0               11.1   \n",
       "4421                                               0               13.9   \n",
       "4422                                               0                9.4   \n",
       "4423                                               0               12.7   \n",
       "\n",
       "      Inflation rate   GDP  Target  \n",
       "0                1.4  1.74       0  \n",
       "1               -0.3  0.79       1  \n",
       "2                1.4  1.74       0  \n",
       "3               -0.8 -3.12       1  \n",
       "4               -0.3  0.79       1  \n",
       "...              ...   ...     ...  \n",
       "4419             2.8 -4.06       1  \n",
       "4420             0.6  2.02       0  \n",
       "4421            -0.3  0.79       0  \n",
       "4422            -0.8 -3.12       1  \n",
       "4423             3.7 -1.70       1  \n",
       "\n",
       "[4424 rows x 35 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06550748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2\n",
       "0  1  0  0\n",
       "1  0  1  0\n",
       "2  1  0  0\n",
       "3  0  1  0\n",
       "4  0  1  0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for the neural network, we do need to split y into 3 columns\n",
    "final_y = pd.get_dummies(y['Target'])\n",
    "final_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c543903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(final_df, final_y, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "076c9398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 70)                2520      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 30)                2130      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4743 (18.53 KB)\n",
      "Trainable params: 4743 (18.53 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model 1 - Sequential, 70 > 30 neurons, 100 epochs\n",
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = X_train.shape[1] # number of columns\n",
    "hidden_nodes_layer1 = 70\n",
    "hidden_nodes_layer2 = 30\n",
    "nn = Sequential()\n",
    "\n",
    "# layers\n",
    "nn.add(Dense(units = hidden_nodes_layer1, activation = 'relu', input_dim = number_input_features))\n",
    "nn.add(Dense(units = hidden_nodes_layer2, activation = 'relu'))\n",
    "nn.add(Dense(units = y_train.shape[1], activation = 'sigmoid'))\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "769409eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "104/104 [==============================] - 1s 1ms/step - loss: 0.5300 - accuracy: 0.6519\n",
      "Epoch 2/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.3913 - accuracy: 0.7266\n",
      "Epoch 3/100\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.3662 - accuracy: 0.7483\n",
      "Epoch 4/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.3547 - accuracy: 0.7634\n",
      "Epoch 5/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.3479 - accuracy: 0.7719\n",
      "Epoch 6/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.3424 - accuracy: 0.7728\n",
      "Epoch 7/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.3375 - accuracy: 0.7821\n",
      "Epoch 8/100\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.3324 - accuracy: 0.7848\n",
      "Epoch 9/100\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.7866\n",
      "Epoch 10/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.3253 - accuracy: 0.7854\n",
      "Epoch 11/100\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.3223 - accuracy: 0.7863\n",
      "Epoch 12/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.3180 - accuracy: 0.7939\n",
      "Epoch 13/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.3140 - accuracy: 0.7996\n",
      "Epoch 14/100\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.3106 - accuracy: 0.7996\n",
      "Epoch 15/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.3080 - accuracy: 0.8029\n",
      "Epoch 16/100\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.3040 - accuracy: 0.8038\n",
      "Epoch 17/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.3003 - accuracy: 0.8068\n",
      "Epoch 18/100\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.2980 - accuracy: 0.8086\n",
      "Epoch 19/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.2949 - accuracy: 0.8086\n",
      "Epoch 20/100\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.2910 - accuracy: 0.8113\n",
      "Epoch 21/100\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.2891 - accuracy: 0.8140\n",
      "Epoch 22/100\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.2832 - accuracy: 0.8180\n",
      "Epoch 23/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.2798 - accuracy: 0.8246\n",
      "Epoch 24/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.2794 - accuracy: 0.8195\n",
      "Epoch 25/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.2740 - accuracy: 0.8261\n",
      "Epoch 26/100\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.2721 - accuracy: 0.8288\n",
      "Epoch 27/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.2692 - accuracy: 0.8258\n",
      "Epoch 28/100\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.2659 - accuracy: 0.8309\n",
      "Epoch 29/100\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.2610 - accuracy: 0.8357\n",
      "Epoch 30/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.2586 - accuracy: 0.8369\n",
      "Epoch 31/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.2559 - accuracy: 0.8376\n",
      "Epoch 32/100\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.2527 - accuracy: 0.8448\n",
      "Epoch 33/100\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.2492 - accuracy: 0.8487\n",
      "Epoch 34/100\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.2476 - accuracy: 0.8409\n",
      "Epoch 35/100\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.2471 - accuracy: 0.8463\n",
      "Epoch 36/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.2414 - accuracy: 0.8481\n",
      "Epoch 37/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.2409 - accuracy: 0.8499\n",
      "Epoch 38/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.2346 - accuracy: 0.8574\n",
      "Epoch 39/100\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.2348 - accuracy: 0.8544\n",
      "Epoch 40/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.2295 - accuracy: 0.8608\n",
      "Epoch 41/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.2274 - accuracy: 0.8668\n",
      "Epoch 42/100\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.2255 - accuracy: 0.8632\n",
      "Epoch 43/100\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.2234 - accuracy: 0.8656\n",
      "Epoch 44/100\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.2210 - accuracy: 0.8719\n",
      "Epoch 45/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.2186 - accuracy: 0.8662\n",
      "Epoch 46/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.2161 - accuracy: 0.8761\n",
      "Epoch 47/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.2142 - accuracy: 0.8710\n",
      "Epoch 48/100\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.2110 - accuracy: 0.8770\n",
      "Epoch 49/100\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.2067 - accuracy: 0.8785\n",
      "Epoch 50/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.2069 - accuracy: 0.8816\n",
      "Epoch 51/100\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.2046 - accuracy: 0.8794\n",
      "Epoch 52/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.2009 - accuracy: 0.8843\n",
      "Epoch 53/100\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.2006 - accuracy: 0.8819\n",
      "Epoch 54/100\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1967 - accuracy: 0.8897\n",
      "Epoch 55/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1952 - accuracy: 0.8882\n",
      "Epoch 56/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1942 - accuracy: 0.8945\n",
      "Epoch 57/100\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1905 - accuracy: 0.8927\n",
      "Epoch 58/100\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1889 - accuracy: 0.8972\n",
      "Epoch 59/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1865 - accuracy: 0.8978\n",
      "Epoch 60/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1841 - accuracy: 0.8945\n",
      "Epoch 61/100\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1810 - accuracy: 0.8996\n",
      "Epoch 62/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1808 - accuracy: 0.9024\n",
      "Epoch 63/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1794 - accuracy: 0.9008\n",
      "Epoch 64/100\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1757 - accuracy: 0.9036\n",
      "Epoch 65/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1749 - accuracy: 0.9051\n",
      "Epoch 66/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1725 - accuracy: 0.9036\n",
      "Epoch 67/100\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1714 - accuracy: 0.9081\n",
      "Epoch 68/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1694 - accuracy: 0.9081\n",
      "Epoch 69/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1682 - accuracy: 0.9117\n",
      "Epoch 70/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1655 - accuracy: 0.9120\n",
      "Epoch 71/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1636 - accuracy: 0.9102\n",
      "Epoch 72/100\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1616 - accuracy: 0.9147\n",
      "Epoch 73/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1589 - accuracy: 0.9159\n",
      "Epoch 74/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1569 - accuracy: 0.9198\n",
      "Epoch 75/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1543 - accuracy: 0.9162\n",
      "Epoch 76/100\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1535 - accuracy: 0.9159\n",
      "Epoch 77/100\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1524 - accuracy: 0.9183\n",
      "Epoch 78/100\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1521 - accuracy: 0.9192\n",
      "Epoch 79/100\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1485 - accuracy: 0.9244\n",
      "Epoch 80/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1452 - accuracy: 0.9244\n",
      "Epoch 81/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1458 - accuracy: 0.9228\n",
      "Epoch 82/100\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1454 - accuracy: 0.9213\n",
      "Epoch 83/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1448 - accuracy: 0.9253\n",
      "Epoch 84/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1399 - accuracy: 0.9283\n",
      "Epoch 85/100\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1430 - accuracy: 0.9280\n",
      "Epoch 86/100\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1376 - accuracy: 0.9325\n",
      "Epoch 87/100\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1356 - accuracy: 0.9322\n",
      "Epoch 88/100\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1339 - accuracy: 0.9331\n",
      "Epoch 89/100\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1323 - accuracy: 0.9346\n",
      "Epoch 90/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1305 - accuracy: 0.9325\n",
      "Epoch 91/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1287 - accuracy: 0.9352\n",
      "Epoch 92/100\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1282 - accuracy: 0.9376\n",
      "Epoch 93/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1265 - accuracy: 0.9385\n",
      "Epoch 94/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1250 - accuracy: 0.9388\n",
      "Epoch 95/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1242 - accuracy: 0.9370\n",
      "Epoch 96/100\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1217 - accuracy: 0.9409\n",
      "Epoch 97/100\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1221 - accuracy: 0.9397\n",
      "Epoch 98/100\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1194 - accuracy: 0.9415\n",
      "Epoch 99/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1160 - accuracy: 0.9488\n",
      "Epoch 100/100\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1161 - accuracy: 0.9470\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1e945ff6350>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile & train\n",
    "nn.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "nn.fit(X_train, y_train, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7bb0a5bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 939us/step\n",
      "35/35 - 0s - loss: 0.5438 - accuracy: 0.7505 - 49ms/epoch - 1ms/step\n",
      "Loss: 0.5437610745429993, Accuracy: 0.7504521012306213\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Dropout       0.75      0.77      0.76       353\n",
      "    Graduate       0.85      0.83      0.84       560\n",
      "    Enrolled       0.47      0.47      0.47       193\n",
      "\n",
      "    accuracy                           0.75      1106\n",
      "   macro avg       0.69      0.69      0.69      1106\n",
      "weighted avg       0.75      0.75      0.75      1106\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[273,  33,  47],\n",
       "       [ 37, 467,  56],\n",
       "       [ 56,  47,  90]], dtype=int64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict and score\n",
    "predicts = pd.DataFrame(nn.predict(X_test), columns = [0, 1, 2])\n",
    "\n",
    "model_loss, model_accuracy = nn.evaluate(X_test, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "print(classification_report(y_test.idxmax(axis = 1), predicts.idxmax(axis = 1), target_names = target_names))\n",
    "confusion_matrix(y_test.idxmax(axis = 1), predicts.idxmax(axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fb8c06d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_21 (Dense)            (None, 100)               3600      \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 30)                3030      \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6723 (26.26 KB)\n",
      "Trainable params: 6723 (26.26 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model 2 - Sequential, 100 > 30 neurons, 100 epochs\n",
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = X_train.shape[1] # number of columns\n",
    "hidden_nodes_layer1 = 100\n",
    "hidden_nodes_layer2 = 30\n",
    "nn = Sequential()\n",
    "\n",
    "# layers\n",
    "nn.add(Dense(units = hidden_nodes_layer1, activation = 'relu', input_dim = number_input_features))\n",
    "nn.add(Dense(units = hidden_nodes_layer2, activation = 'relu'))\n",
    "nn.add(Dense(units = y_train.shape[1], activation = 'sigmoid'))\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "57192dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "104/104 [==============================] - 1s 2ms/step - loss: 0.4950 - accuracy: 0.6495\n",
      "Epoch 2/75\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.3844 - accuracy: 0.7450\n",
      "Epoch 3/75\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.3607 - accuracy: 0.7628\n",
      "Epoch 4/75\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.3486 - accuracy: 0.7703\n",
      "Epoch 5/75\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.3411 - accuracy: 0.7782\n",
      "Epoch 6/75\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.3350 - accuracy: 0.7752\n",
      "Epoch 7/75\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.3306 - accuracy: 0.7824\n",
      "Epoch 8/75\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.3238 - accuracy: 0.7905\n",
      "Epoch 9/75\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.3213 - accuracy: 0.7896\n",
      "Epoch 10/75\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.3148 - accuracy: 0.7966\n",
      "Epoch 11/75\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.3116 - accuracy: 0.7975\n",
      "Epoch 12/75\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.3077 - accuracy: 0.8014\n",
      "Epoch 13/75\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.3023 - accuracy: 0.8044\n",
      "Epoch 14/75\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.2977 - accuracy: 0.8071\n",
      "Epoch 15/75\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.2944 - accuracy: 0.8098\n",
      "Epoch 16/75\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.2907 - accuracy: 0.8107\n",
      "Epoch 17/75\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.2858 - accuracy: 0.8143\n",
      "Epoch 18/75\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.2823 - accuracy: 0.8153\n",
      "Epoch 19/75\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.2787 - accuracy: 0.8198\n",
      "Epoch 20/75\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.2762 - accuracy: 0.8231\n",
      "Epoch 21/75\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.2710 - accuracy: 0.8267\n",
      "Epoch 22/75\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.2687 - accuracy: 0.8288\n",
      "Epoch 23/75\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.2627 - accuracy: 0.8315\n",
      "Epoch 24/75\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.2611 - accuracy: 0.8318\n",
      "Epoch 25/75\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.2584 - accuracy: 0.8318\n",
      "Epoch 26/75\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.2547 - accuracy: 0.8388\n",
      "Epoch 27/75\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.2490 - accuracy: 0.8439\n",
      "Epoch 28/75\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.8454\n",
      "Epoch 29/75\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.2433 - accuracy: 0.8454\n",
      "Epoch 30/75\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.2386 - accuracy: 0.8511\n",
      "Epoch 31/75\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.2353 - accuracy: 0.8547\n",
      "Epoch 32/75\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.2323 - accuracy: 0.8544\n",
      "Epoch 33/75\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.2279 - accuracy: 0.8593\n",
      "Epoch 34/75\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.2242 - accuracy: 0.8611\n",
      "Epoch 35/75\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.2216 - accuracy: 0.8623\n",
      "Epoch 36/75\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.2173 - accuracy: 0.8704\n",
      "Epoch 37/75\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.2166 - accuracy: 0.8644\n",
      "Epoch 38/75\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.2118 - accuracy: 0.8713\n",
      "Epoch 39/75\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.2097 - accuracy: 0.8722\n",
      "Epoch 40/75\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.2047 - accuracy: 0.8803\n",
      "Epoch 41/75\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.2032 - accuracy: 0.8807\n",
      "Epoch 42/75\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1987 - accuracy: 0.8828\n",
      "Epoch 43/75\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1968 - accuracy: 0.8858\n",
      "Epoch 44/75\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1912 - accuracy: 0.8894\n",
      "Epoch 45/75\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1907 - accuracy: 0.8924\n",
      "Epoch 46/75\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1865 - accuracy: 0.8918\n",
      "Epoch 47/75\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1833 - accuracy: 0.8984\n",
      "Epoch 48/75\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1838 - accuracy: 0.8939\n",
      "Epoch 49/75\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1777 - accuracy: 0.8987\n",
      "Epoch 50/75\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1764 - accuracy: 0.9020\n",
      "Epoch 51/75\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1735 - accuracy: 0.9014\n",
      "Epoch 52/75\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1717 - accuracy: 0.9014\n",
      "Epoch 53/75\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1691 - accuracy: 0.9069\n",
      "Epoch 54/75\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1641 - accuracy: 0.9114\n",
      "Epoch 55/75\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1652 - accuracy: 0.9054\n",
      "Epoch 56/75\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1596 - accuracy: 0.9141\n",
      "Epoch 57/75\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1562 - accuracy: 0.9174\n",
      "Epoch 58/75\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1539 - accuracy: 0.9192\n",
      "Epoch 59/75\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1530 - accuracy: 0.9105\n",
      "Epoch 60/75\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1490 - accuracy: 0.9192\n",
      "Epoch 61/75\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1465 - accuracy: 0.9219\n",
      "Epoch 62/75\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1436 - accuracy: 0.9234\n",
      "Epoch 63/75\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1432 - accuracy: 0.9207\n",
      "Epoch 64/75\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1400 - accuracy: 0.9277\n",
      "Epoch 65/75\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1378 - accuracy: 0.9268\n",
      "Epoch 66/75\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1351 - accuracy: 0.9325\n",
      "Epoch 67/75\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1353 - accuracy: 0.9310\n",
      "Epoch 68/75\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1306 - accuracy: 0.9295\n",
      "Epoch 69/75\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1299 - accuracy: 0.9310\n",
      "Epoch 70/75\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1253 - accuracy: 0.9349\n",
      "Epoch 71/75\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1234 - accuracy: 0.9400\n",
      "Epoch 72/75\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1207 - accuracy: 0.9385\n",
      "Epoch 73/75\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1211 - accuracy: 0.9394\n",
      "Epoch 74/75\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1204 - accuracy: 0.9406\n",
      "Epoch 75/75\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1181 - accuracy: 0.9436\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1e94d31ad10>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile & train\n",
    "nn.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "nn.fit(X_train, y_train, epochs = 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "22e4b114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 1ms/step\n",
      "35/35 - 0s - loss: 0.5638 - accuracy: 0.7486 - 127ms/epoch - 4ms/step\n",
      "Loss: 0.5637906193733215, Accuracy: 0.7486437559127808\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Dropout       0.75      0.76      0.76       353\n",
      "    Graduate       0.84      0.86      0.85       560\n",
      "    Enrolled       0.44      0.39      0.41       193\n",
      "\n",
      "    accuracy                           0.75      1106\n",
      "   macro avg       0.68      0.67      0.67      1106\n",
      "weighted avg       0.74      0.75      0.74      1106\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[270,  41,  42],\n",
       "       [ 25, 483,  52],\n",
       "       [ 65,  53,  75]], dtype=int64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict and score\n",
    "predicts = pd.DataFrame(nn.predict(X_test), columns = [0, 1, 2])\n",
    "\n",
    "model_loss, model_accuracy = nn.evaluate(X_test, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "print(classification_report(y_test.idxmax(axis = 1), predicts.idxmax(axis = 1), target_names = target_names))\n",
    "confusion_matrix(y_test.idxmax(axis = 1), predicts.idxmax(axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9930ab6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
